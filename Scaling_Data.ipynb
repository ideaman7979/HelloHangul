{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Rescaling method.\n",
    "\"\"\"\n",
    "def rescaling_img(o_list):\n",
    "    o_h=len(o_list)\n",
    "    o_w=len(o_list[0])\n",
    "    n_h=64\n",
    "    n_w=64\n",
    "    n_list = [[0 for col in range(n_w)] for row in range(n_h)]\n",
    "    \n",
    "    for i in range(n_w):\n",
    "        n_list[0][i]=255\n",
    "        n_list[n_h - 1][i]=255\n",
    "        \n",
    "    for n_y in range(1,n_h - 1):\n",
    "        o_y = int(n_y * o_h / n_h) \n",
    "        n_list[n_y][0] = 255\n",
    "        n_list[n_y][n_w - 1] = 255\n",
    "        for n_x in range(1,n_w-1):\n",
    "            o_x = int(n_x * o_w / n_w)\n",
    "            n_list[n_y][n_x] = o_list[o_y][o_x]\n",
    "    return n_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_files(origin_path, dest_path, data_name):\n",
    "   \n",
    "    n_h=64\n",
    "    n_w=64\n",
    "    # read files \n",
    "    file_list=os.listdir(origin_path+data_name)\n",
    "    \n",
    "    for fine_no in range(len(file_list)):\n",
    "    # file open\n",
    "        EOF=False\n",
    "        myfile=file_list[fine_no]\n",
    "        f = open(origin_path+data_name+ myfile, 'rb')\n",
    "        r_f = open(dest_path+data_name+'r_'+myfile, 'wb+')\n",
    "        file_header = f.read(8)\n",
    "        r_f.write(file_header)\n",
    "    \n",
    "    # Read Images\n",
    "    \n",
    "        while EOF==False : \n",
    "        # read code & check EoF\n",
    "            code = f.read(2)\n",
    "            \n",
    "            if (len(code) < 2) :\n",
    "                break\n",
    "    \n",
    "            width=f.read(1)[0]\n",
    "            height = f.read(1)[0]\n",
    "            buffer=[]\n",
    "            reserved = f.read(2)\n",
    "            for i in range(height):\n",
    "                buffer2=[]\n",
    "                for j in range(width):\n",
    "                    data=int.from_bytes(f.read(1), byteorder='big')\n",
    "                    buffer2.append(data)\n",
    "                    #print(data, end=' ')\n",
    "                buffer.append(buffer2)\n",
    "                #print(buffer)\n",
    "        \n",
    "            s_image=rescaling_img(buffer)\n",
    "            r_f.write(code)\n",
    "            r_f.write(n_h.to_bytes(1, byteorder='big',signed=False))\n",
    "            r_f.write(n_w.to_bytes(1, byteorder='big',signed=False))\n",
    "            r_f.write(reserved)\n",
    "            for i in range(n_h):\n",
    "                for j in range(n_w):\n",
    "                    r_f.write(s_image[i][j].to_bytes(1, byteorder='big',signed=False))\n",
    "        # Reading file done\n",
    "        f.close()\n",
    "        r_f.close()\n",
    "        #print(\"File \"+str(fine_no)+\" is rescaled\")\n",
    "        # Read Next file\n",
    "    print(data_name+\"are done!!\")\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\PE92_train\\are done!!\n",
      "\\HanDB_test\\are done!!\n",
      "\\HanDB_train\\are done!!\n",
      "\\SERI_Test\\are done!!\n",
      "\\SERI_Train\\are done!!\n"
     ]
    }
   ],
   "source": [
    "Origin_Path='C:\\\\Tensorflow\\\\HangulDB'\n",
    "Scaled_Path='C:\\\\Tensorflow\\\\Rescaled_DB'\n",
    "hanDB_train='\\\\HanDB_train\\\\'\n",
    "hanDB_test='\\\\HanDB_test\\\\'\n",
    "PE92_test=\"\\\\PE92_test\\\\\"\n",
    "PE92_train=\"\\\\PE92_train\\\\\"\n",
    "SERI_test=\"\\\\SERI_Test\\\\\"\n",
    "SERI_train=\"\\\\SERI_Train\\\\\"\n",
    "\n",
    "\n",
    "#len(file_list) # 2350 classes\n",
    "\n",
    "#scaling_files(Origin_Path, Scaled_Path, PE92_test)\n",
    "#scaling_files(Origin_Path, Scaled_Path, PE92_train)\n",
    "#scaling_files(Origin_Path, Scaled_Path, hanDB_test)\n",
    "scaling_files(Origin_Path, Scaled_Path, hanDB_train)\n",
    "#scaling_files(Origin_Path, Scaled_Path, SERI_test)\n",
    "#scaling_files(Origin_Path, Scaled_Path, SERI_train)\n",
    "\n",
    "\n",
    "#print(file_list) \n",
    "#myfile=file_list\n",
    "#print(myfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\HanDB_train\\are done!!\n"
     ]
    }
   ],
   "source": [
    "origin_path='C:\\\\Tensorflow\\\\HangulDB'\n",
    "dest_path = 'C:\\\\Tensorflow\\\\Rescaled_DB'\n",
    "data_name = '\\\\HanDB_train\\\\'\n",
    "   \n",
    "n_h=64\n",
    "n_w=64\n",
    "    # read files \n",
    "file_list=os.listdir(origin_path+data_name)\n",
    "    \n",
    "myfile=\"bfaf.hgu1\"\n",
    "f = open(origin_path+data_name+ myfile, 'rb')\n",
    "r_f = open(dest_path+data_name+'r_'+myfile, 'wb+')\n",
    "file_header = f.read(8)\n",
    "r_f.write(file_header)\n",
    "    \n",
    "    # Read Images\n",
    "    \n",
    "while True : \n",
    "        # read code & check EoF\n",
    "    code = f.read(2)\n",
    "            \n",
    "    if (len(code) < 2) :\n",
    "        break\n",
    "    \n",
    "    width=f.read(1)[0]\n",
    "    height = f.read(1)[0]\n",
    "    buffer=[]\n",
    "    reserved = f.read(2)\n",
    "    for i in range(height):\n",
    "        buffer2=[]\n",
    "        for j in range(width):\n",
    "            data=int.from_bytes(f.read(1), byteorder='big')\n",
    "            buffer2.append(data)\n",
    "                    #print(data, end=' ')\n",
    "        buffer.append(buffer2)\n",
    "                #print(buffer)\n",
    "        \n",
    "    s_image=rescaling_img(buffer)\n",
    "    r_f.write(code)\n",
    "    r_f.write(n_h.to_bytes(1, byteorder='big',signed=False))\n",
    "    r_f.write(n_w.to_bytes(1, byteorder='big',signed=False))\n",
    "    r_f.write(reserved)\n",
    "    for i in range(n_h):\n",
    "        for j in range(n_w):\n",
    "            r_f.write(s_image[i][j].to_bytes(1, byteorder='big',signed=False))\n",
    "        # Reading file done\n",
    "f.close()\n",
    "r_f.close()\n",
    "        #print(\"File \"+str(fine_no)+\" is rescaled\")\n",
    "        # Read Next file\n",
    "print(data_name+\"are done!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
